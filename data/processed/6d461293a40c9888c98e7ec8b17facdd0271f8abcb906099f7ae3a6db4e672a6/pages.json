[
  {
    "page_number": 1,
    "text": "Large-Scale Knowledge Synthesis and Complex\nInformation Retrieval from Biomedical Documents\nShreya Saxena* , Raj Sangani*, Siva Prasad*, Shubham Kumar*\nMihir Athale*, Rohan Awhad*, Vishal Vaddina+\nApplied Research, Quantiphi\n{shreya.saxena, siva.prasad, shubham.kumar01, mihir.athale, rohan.awhad, vishal.vaddina}@quantiphi.com\nrsangani@ucdavis.edu\nAbstract—Recentadvancesinthehealthcareindustryhaveled [5], and statistical language models, which aim to find an\nto an abundance of unstructured data, making it challenging to exact match between the query and documents but fail to\nperformtaskssuchasefficientandaccurateinformationretrieval\nhandle the problem of vocabulary and semantic mismatch.\nat scale. Our work offers an all-in-one scalable solution for\nEarlier studies in neural IR handle the problem of vocabulary\nextracting and exploring complex information from large-scale\nresearch documents, which would otherwise be tedious. First, mismatch by taking a different approach, such as maximum\nwe briefly explain our knowledge synthesis process to extract innerproductsearch(MIPS)betweenGLoVe[6]orWord2vec\nhelpful information from unstructured text data of research [7] embeddings of query and document terms. The problem\ndocuments. Then, on top of the knowledge extracted from the\nof semantic mismatch was solved by leveraging contextual\ndocuments, we perform complex information retrieval using\nembeddings with the introduction of language models [8].\nthree major components- Paragraph Retrieval, Triplet Retrieval\nfrom Knowledge Graphs, and Complex Question Answering Lexical systems might fail to capture the semantics of the\n(QA). These components combine lexical and semantic-based concepts, especially in biomedical data with complex terms\nmethodstoretrieveparagraphsandtripletsandperformfaceted that sometimes are quite ambiguous. Semantic systems can\nrefinement for filtering these search results. The complexity of\nhandle this ambiguity well, but these systems often have dif-\nbiomedicalqueriesanddocumentsnecessitatesusingaQAsystem\nficulty dealing with longer contexts. Hence, we need a hybrid\ncapable of handling queries more complex than factoid queries,\nwhichweevaluatequalitativelyontheCOVID-19OpenResearch framework that can accommodate both of these mechanisms.\nDataset (CORD-19) to demonstrate the effectiveness and value- This paper conceptualizes a framework to help users access\nadd. meaningful information extracted from massive corpora in\nthe biomedical domain. They can explore the information\nIndex Terms—Information-Retrieval, Knowledge-Synthesis,\nin the form of knowledge graphs (Section III.A), search for\nSemantic-Retrieval, Question-Answering, CORD-19\nspecificinformation,andgetanswerstocomplexquestionsi.e,\nquestions that require multiple contexts to provide an answer\nI. INTRODUCTION\n(e.g. “What virus was isolated from a patient who died from\nThe healthcare sector stands tall with an enormous amount\nacute respiratory failure?”).\nof unstructured text data in documents, articles, biomedical\nWe propose an all-in-one information retrieval framework\njournals, and JSON files, as well as structured data like\nusing lexical and semantic approaches, shown in Fig.1, that\ntables, and electronic health records, often leading to a severe\ncombinesmultiplefunctionalitieslikepassageretrieval;triplet\ninformation overload challenge. To researchers and health\nretrievalfromknowledgegraphsandcomplexQA.Wealsoin-\nprofessionals, extracting relevant information from a huge\nclude faceted navigation for filtering the triplet search results,\ncorpus of biomedical data is a complex and tedious task that\nmaking it easier for the user to explore relevant information\ndelaystheresearchoutcomeandinvolvesconsiderablecapital.\nthroughalargeamountofdata.Ourquestionansweringsystem\nTherefore, there is an increased urgency for an information\ncan answer complex queries by integrating multi-hop dense\nretrieval system in the biomedical domain to retrieve such\nretriever [9], which uses a dense iterative retrieval method.\ncomplex information.\nThe following describes how the paper is structured: Back-\nInformation Retrieval (IR) is a core task in many real-world\nground information is provided in Section-II. The methodol-\napplications, such as digital libraries, expert finding, web\nogy is then discussed in Section-III with distinct subsections\nsearch and others. Information retrieval aims at retrieving\nfor its various components, experiments are discussed in\ninformation relevant to a query from large data collections,\nSection-IV, and Section-V concludes the paper.\nwhich has been an active research area in the healthcare\ndomain [2] [3] [4]. Traditional information retrieval systems II. BACKGROUND\nrely on lexical retrievers such as Boolean Retrieval, BM25\nTo researchers and health professionals, extracting relevant\ninformation from a huge corpus of medical research docu-\n* Equalcontribution,+ Correspondingauthor\nments and texts is a complex, time-consuming, and tedious\nShorterversionofthisworkispublishedatIEEEBigData2022Conference,\nheldatOsaka,Japan[1]DOI:10.1109/BigData55660.2022.10020725 task that delays the research outcome and involves consid-\n3202\nbeF\n41\n]RI.sc[\n1v45860.2032:viXra",
    "tables": [],
    "text_stats": {
      "word_count": 636,
      "char_count": 5218,
      "line_count": 85,
      "table_count": 0
    }
  },
  {
    "page_number": 2,
    "text": "erable capital, yet is a necessity. Therefore, there has been a) Knowledge graph construction: We first clean and\nan increased urgency for an information retrieval system in preprocess the text from research documents. This data is\nthe medical domain to retrieve such complex information indexed for further use by the retrievers to retrieve relevant\n[10]. Recent years have witnessed an increase in information contexts.Thenwepassthistextthroughourknowledgegraph\nretrieval systems in the healthcare domain, such as a medical construction pipeline, which is as follows:-\ninformation retrieval system for e-healthcare records [11], 1) Coreference Resolution on the sentences.\nretrievalofsemanticallysimilarquestionsinhealthcareforums 2) Extracting triplets (subject, relation, object pairs) using\n[12], and a system that uses information retrieval with an the Open Information Extraction (OpenIE 6) System\nadded component for classifying breast cancer [13]. [27] from sentences.\nDue to the pandemic, information extraction around COVID- 3) Canonicalization of the extracted relations.\n19 data has emerged as an active research area [14], predom- 4) Linking extracted entities to appropriate ontology.\ninantly using knowledge graphs [15] [16]. Complex question The above pipeline results in the formation of a knowledge\nanswering,especiallyinthemedicaldomain,hasalsobecome graph, which consists of canonicalized and linked triplets,\nprominent [17]. These systems try to solve problems like extracted from the biomedical documents. We also include\nknowledge graph (KG) generation on structured data, factoid metadata such as Authors, Institutions, Publication Year, etc.\nquestion answering and searching entities in the KG [18]. along with textual phrases from the original documents.\nThesesystemsfailtoaddresstheseusecasescomprehensively.\nB. Complex Information Retrieval\nFor example, the KG created might be ontology specific and\ncannot capture facts from open text or might only represent OurComplexInformationRetrievalsystemconsistsofthree\nmetadata information in the form of a graph; these systems maincomponents:-ParagraphRetrieval,TripletRetrieval,and\nalsofailtoprovideanefficientintegratedsearch[19][20]and Complex Question Answering. We also have a spell checker\nQA functionality such as ours. that corrects spelling errors in the query asked by the user.\nRecent transformer-based retrievers mostly rely on the max- Spell correction: Often queries include misspelled terms\nimum inner product search between the dense representation resulting in irrelevant results. Therefore, a spell correction\nof the query and the documents, generated using transformer module trained on biomedical text is deployed to correct\nmodels.Theseretriever-basedsystemsareoftensupportedbya the query before handing it over to the retrievers, enabling\nre-ranker,basedonvariantsoftransformermodelslikeSBERT the system to handle adversarial examples of misspelled\nand BERT-based cross-encoders [21]. terms robustly. The module is based on [28], which uses\nPrevious work on Open Domain Question Answering [22] is Levenshtein Distance (edit distance) and the probability of\nmainly based on retriever and reader architecture, Iterative the word appearing in the document.\nRetriever, Reader, Reranker (IRRR) [23], which captures an\ninitial set of keywords from the query, expands it based on\ncorrection(w)=argmax P(c|w) (1)\nthe passages it retrieves from the database and re-ranks them. c∈candidates\nThese re-ranked passages are then passed to the reader to Out of all possible candidate corrections, having an edit\ngenerateanswers,andthewholeprocessisiterativelyrepeated distance of 2 or less, the algorithm finds the correction c that\nuntil the answer is found with high confidence. All of this maximizes the probability that c is the intended correction,\nmakes the IRRR based systems highly complex due to the given the original word w.\nlargenumberofcomponentsinvolved,coupledwithlongerin- 1) ParagraphRetrieval: Toretrievethemostrelevantpiece\nference time and higher memory consumption. Other retrieval of information from indexed documents, we introduce the\nmethods use graph-based knowledge along with transformer paragraph retrieval functionality, where one paragraph is con-\nmodels to find multi-hop reasoning paths [24] [25]. sidered a unit of information and indexed. The retrieval com-\nbines four different search mechanisms viz, phrase search, bi-\nIII. METHODOLOGY gram search, keyword search and semantic search. For all the\nmechanisms, we use ElasticSearch for indexing. We employ\nInthissection,weexplaintheproposedmodelarchitecture.\na cross-encoder to re-rank the results based on their relevance\nWe use CORD-19 [26] as an example dataset for explaining\nto the given query.\nthe pipeline and process throughout this paper, although the\na) PhraseSearch: Phrasesearchfindsanexactmatchfor\nentire framework is flexible and should be translatable to a\nthe entire query or a part of the query, which can be specified\nvariety of datasets in biomedical literature.\nby encoding the phrase in double quotes, e.g. Human “SARS-\nCoV” infection where we retrieve the relevant documents by\nA. Knowledge Synthesis\nmatching the exact phrase “SARS-CoV”.\nIn the biomedical domain, data may be present in the form b) Bi-gram Search: Bi-gram search splits the query into\nofblogs,articles,researchpapers,clinicaldocuments,etc.We pairsofwords,calledbi-grams.Thesebi-gramsaresubstrings\nadopt a knowledge synthesis process to extract information in of the query. The system searches the paragraph corpus for\nthe form of subject-relation-object triplets from such unstruc- exact matches of these bi-grams (e.g. Real-time PCR assay ¿\ntured text documents. [‘Real-time PCR’, “PCR assay’]).",
    "tables": [],
    "text_stats": {
      "word_count": 756,
      "char_count": 5751,
      "line_count": 64,
      "table_count": 0
    }
  },
  {
    "page_number": 3,
    "text": "Query : Flow of Framework\n: Component Interaction\nUnstructured Text in\nDocuments\nParagraph Triplet Complex QA\nRetrieval Retrieval\nSpell Checker Multi-Hop Dense\nSpell Checker Retriever\nPreprocessing\nRe-Ranking Re-Ranking\nPhrase Search (Cross Encoder) Filters (Cross Encoder)\nIndex Reader\nBi-Gram Re-Ranking Triplet Search with\nPhrase Search (Cross Encoder) Metadata Extractive Reader\n(RoBERTa)\nRe-Ranking\nElastic Search Keyword Search (Cross Encoder) Generative Reader\n(FiD)\nRetrieved\nParagraphs, Triplets, Answer\nMetadata, Answer\nFig.1. ArchitectureofComplexInformationRetrievalSystem.Thequeryispassedthroughallthreecomponentsoftheframework.Theparagraphretrieval\ncombinesresultsfromthephrase,bigram,andkeywordsearchesandretrievesrelevantpassagesfromtheindexeddata.Thetripletretrievalretrievesrelated\nsubject-object-relation pairs from the constructed knowledge graph. The complex question answering system gives an answer to the query along with the\nsemanticallyretrievedpassagesfromtheMulti-hopDenseRetriever(MDR).\nc) KeywordSearch: Thismethodtokenizesthequeryand andobjecttypesandsubtypesasfacetsandjoinmultiplesuch\nsearches through the corpus for matches and retrieves them in facets using a boolean AND condition to filter the retrieved\norder of the count of matches in the specific paragraph. We results.\nuse an Edge n-gram tokenizer with n being set to a minimum a) Triplet Index Construction: While indexing the data\nvalueof4andamaximumvalueof30.Thesimilarityfunction into the ElasticServer we use the following custom settings\nwe use in this method is Okapi BM25 [5]. and analyzer for preprocessing the raw JSON data:-\nRe-rankingtheresultsTore-ranktheretrievedresultsbased\n1) TokenizethedocumentsusingtheEdgen grammethod.\non relevance to the query, we use a MiniLM cross-encoder\n2) Filter the tokens to lowercase and ASCII folding.\n[29]trainedonMSMARCO[30]isused.Thismodeloutputs\na relevancy score between 0 and 1 for every paragraph paired b) Retrieval: The triplet retrieval component consists of\nwith the query. The order is decided based on this score with the same similarity functions and search mechanisms used\n1 being the highest. beforeviz.phrasesearch,bi-gramsearch,andkeywordsearch.\nRetrieved Paragraphs The results list consists of a prede- The results here consist of a list of triplets each containing\nfined number of paragraphs (r). The passages are retrieved subject, relation, and object. Additionally, we utilize triplet\nusing phrase, bi-gram, and keyword search, in the respective metadatalikealiases,types,subtypes,descriptions,etc.Higher\norder. This ordering is based on descending precision for weightageisgiventothesubject,object,andrelationtripletas\nindividual mechanisms. We combine these passages with the compared to the metadata. Here, the weights can be manually\npassagesretrievedusingsemanticsearch,fromtheretrieverof tuned or trained.\nthe complex QA system. The retrieval process continues until c) Faceted Refinement: Faceted refinement is employed\nthe length of the results list is less than r (e.g. r=20). to assist researchers to refine the information retrieved using\n2) Triplet Retrieval: To retrieve the most relevant triplets the facet fields as shown in Fig.3. Subject and object types\nfor the query from our large knowledge graph we need the and subtypes are considered facets. Multiple facets are joined\ntriplet retrieval system. This methodology retrieves triplets togetherusingabooleanANDconditionfilteringtheretrieved\n(subject-relation-object) which are constructed using the results.\nKnowledge Synthesis pipeline (Section III.A) for all the d) Knowledge Graph Querying: We also store our\nCORD-19 research papers. An additional feature of faceted knowledge graph in the Neo4j graph database AuraDB with\nrefinement is added on top to refine the results further by a particular schema to run structured queries on top of it for\nspecifying values for different facets. We consider the subject retrieving triplets and subgraphs, using CypherQL [31].",
    "tables": [
      [
        [
          ": Flow of Framework"
        ],
        [
          ": Component Interaction"
        ]
      ],
      [
        [
          "Complex QA"
        ]
      ],
      [
        [
          "Reader Extractive Reader (RoBERTa) Generative Reader (FiD)",
          "Reader"
        ]
      ],
      [
        [
          "Answer"
        ]
      ]
    ],
    "text_stats": {
      "word_count": 485,
      "char_count": 3998,
      "line_count": 55,
      "table_count": 4
    }
  },
  {
    "page_number": 4,
    "text": "virus found in rhinolophus bats\nParagraph Retrieval Triplet Retrieval\nThe discovery of SARS-related CoVs in Kenyan bats adds to the diversity Subject: rhinolophus bats\nand geographic range of CoVs in Rhinolophus bats. Relation: harbor\nObject: wide diversity of covs\nOur long-term surveillances suggest that Rhinolophus bats seem to harbor Subject: Yan Zhu\na wide diversity of CoVs. Relation: Authored\nObject: Characterization of a New Member of Alphacoronavirus with Unique\nGenomic Features in Rhinolophus Bats\nSemantic Search\nGlobal Epidemiology of Bat Coronaviruses\nHowever, there are not sufficient data to establish the prevalence of SARS-like CoVs in different bat host species, especially the species under the\ngenus Rhinolophus. Interestingly, geographical factor does contribute to the diversity of SARS-like CoVs.\nBat Coronaviruses in China\nIt was strongly suggested that SARS-CoV most likely originated from Yunnan Rhinolophus bats via recombination events among existing\nSARSr-CoVs. These studies revealed that various SARSr-CoVs capable of using human ACE2 are still circulating among bats.\nFig.2. ResultsfromComplexInformationRetrievalFrameworkforphrase.Theparagraphretrievalretrievespassagesrelevanttothedetectionofrhinolophus\nbats. The triplet retrieval results subject-relation-object pairs from the knowledge graph. They include entity-relation-entity triplets from the passages and\nmetadatatripletslikedocument-reference-documents.ThesemanticsearchresultscontainpassagesretrievedfromMultihopDenseRetriever(MDR).Asthe\nqueryisaphrase,thereisnoresponsefromthequestion-answeringpipeline.\n3) Complex Question Answering: The Complex Question resultsfromtheMDRwiththeresultsfromparagraphretrieval\nAnswering system can handle factoid questions, e.g. ”Where (Section III.B.1).\nwas coronavirus first discovered?” as well as multi-hop ques- b) Reader: The reader is responsible for providing an\ntionswhichrequiregoingthroughmultiplepassagestoanswer answergivenacontext.Weusetworeadersinourframework:\nthe question, e.g. ”What bats are the main reservoir of the Extractive reader and Generative reader. Extractive readers\nvirus which is transmitted to humans via ACE2 receptor?”.\nextractcontinuousanswerspansfromtheretrievedpassage.In\nWe split the passages from COVID-19 related documents into contrast, generative readers are capable of generating answers\na maximum length of 300 tokens. Then, we pass these fixed even though they may not find them in the context provided.\nlength passages through a transformer encoder to generate For extractive QA we use the RoBERTa model. This model\ndense embeddings for each passage. We store these embed- for question answering takes the question tokens and context\ndings in a dense index for further retrieval. tokens as inputs and predicts the answer start and end tokens.\na) Retriever: The retriever searches through the dense ForgenerativereaderweusetheFusion-in-decoder(FiD)[34].\nindex of CORD-19 documents and retrieves passages relevant\nto the query. To deal with multi-hop questions, we make\nuse of the Multi-hop Dense Retriever (MDR) [9], which is IV. EXPERIMENTS\nan iterative retriever that uses a single RoBERTa-base model\n[32] to encode queries and passages into the same vector A. Dataset\nspace. It is trained to iteratively search and retrieve relevant\ndocuments from the database using Facebook AI Similarity CORD-19 is a corpus of academic papers about COVID-19\nSearch (FAISS) [33]. We have set the number of iterations and related coronavirus research, curated and maintained by\nto 2 in our system, but it is tunable. MDR retrieves two the Allen Institute for AI. The dataset has grown to index\npassages, related to each other based on reasoning paths or over 1M papers and includes full-text content for nearly\ninformation about the entities in question, constituting one 370K papers. Documents from CORD-19 are indexed and\nchain of retrieved contexts. Top-k such chains are retrieved information retrieval is done on top of this index. The reader\nbased on their semantic similarity scores. The chains are then modelsarefine-tunedontheMRQA[35]datasetthatcontains\nsortedbasedonthecombinedsimilarityscoreofthehopsand preprocessedsubsetsofotherdomain-relateddatasets,making\nfurtherre-ranktheretrievedpassagesusingtheMiniLMcross- it a more generalized and suitable benchmark. The reader\nencoder. Then we send the passages to the reader models to is also fine-tuned on Covid-QA [36], a medical question\ngenerate answers. We also merge these semantically retrieved answering dataset around COVID-19.",
    "tables": [
      [
        [
          "virus found in rhinolophus bats",
          ""
        ],
        [
          "Paragraph Retrieval",
          "Triplet Retrieval"
        ],
        [
          "The discovery of SARS-related CoVs in Kenyan bats adds to the diversity and geographic range of CoVs in Rhinolophus bats.",
          "Subject: rhinolophus bats Relation: harbor Object: wide diversity of covs"
        ],
        [
          "Our long-term surveillances suggest that Rhinolophus bats seem to harbor a wide diversity of CoVs.",
          "Subject: Yan Zhu Relation: Authored Object: Characterization of a New Member of Alphacoronavirus with Unique Genomic Features in Rhinolophus Bats"
        ],
        [
          "Semantic Search",
          ""
        ],
        [
          "Global Epidemiology of Bat Coronaviruses However, there are not sufficient data to establish the prevalence of SARS-like CoVs in different bat host species, especially the species under the genus Rhinolophus. Interestingly, geographical factor does contribute to the diversity of SARS-like CoVs.",
          ""
        ],
        [
          "Bat Coronaviruses in China It was strongly suggested that SARS-CoV most likely originated from Yunnan Rhinolophus bats via recombination events among existing SARSr-CoVs. These studies revealed that various SARSr-CoVs capable of using human ACE2 are still circulating among bats.",
          ""
        ]
      ]
    ],
    "text_stats": {
      "word_count": 577,
      "char_count": 4556,
      "line_count": 50,
      "table_count": 1
    }
  },
  {
    "page_number": 5,
    "text": "How many species exist of the mammals that are the main reservoir of coronaviruses?\nParagraph Retrieval Triplet Retrieval\nHigh species diversity (about 1,150 in the world), high mobility and the fact that Subject: Isolation and characterization of a bat SARS-like coronavirus that\nthey represent a source of emerging infections for humans make bats one of the uses the ACE2 receptor\nmost epidemiologically relevant group of mammals to study disease ecology. Relation: References\nObject: Detection of Novel SARS Coronaviruses in Bats\nBats are the second largest order of mammals, comprising more than 1200 different Subject: alpha-coronaviruses\nspecies Relation: may be derived from\nObject: bat coronaviruses\nComplex Question Answering\nQA Response: 1200\nReplication of MERS and SARS coronaviruses in bat cells offers insights to their ancestral origins\nCoronaviruses(CoVs) are important pathogens in animals and humans, responsible for a variety of respiratory, hepatic, and neurological diseases. Bats are an\nimportant reservoir of alpha coronaviruses and beta coronaviruses, which may jump to other species.\nNew Adenovirus Groups in Western Palaearctic Bats\nBats are the second largest order of mammals, comprising more than 1200 different species. Their high vagility and the organization typically in social groups\npredispose them to infection and viral dissemination.\nFig.3. ResultsfromComplexInformationRetrievalFrameworkforamulti-hopquestion.Theparagraphretrievalretrievespassagesrelevanttothequestion.\nThetripletretrievalresultssubject-relation-objectpairsfromtheknowledgegraph.Theyincludeentity-relation-entitytripletsfromthepassagesandmetadata\ntripletslikedocument-reference-documents.Thecomplexquestionansweringsystemfirstretrievesapassagethattalksaboutthemainreservoirofcoronavirus\ni.ebatandthenretrievesapassagethattalksaboutthenumberofspeciesofbats.\nB. Training passage that talks about the number of species of bats (1200),\nwhich can be seen in Fig.3. We also observe that our passage\nThe extractive reader is a RoBERTa-base model, already\nretrieval mechanism retrieves highly relevant passages. They\npre-trained on WikiMultiHop. We initially fine-tune it on a\ncontainthekeywordsinthequeryandarecontextuallysimilar\ngeneralized dataset, MRQA, and then fine-tune it further on\nto the query asked. The triplet retrieval also retrieves the\nCovid-QA for two epochs to learn the biomedical context. To\nbest set of triplets related to the query. Overall our system\navoid losing important information, we split the documents\ncan provide the user with the most relevant information to\npresent in the CORD-19 dataset into chunks of size C, such\nthe query asked using lexical as well semantic retrievers\nthat each chunk contains strides (overlap) of size S with the\nunlike similar information extraction systems around COVID-\npreviouschunk.WemakesurethatCislessthan512,asmost\n19, such as [19] that uses only BM25 for retrieval and not\ntransformer models cannot process tokens more than 512 and\nan iterative retriever like ours that also enables our question\nS is set as 128 to overlap optimal information.\nansweringsystemtoreasonovermorethanonedocumentand\nThe generative reader is the Fusion-in-Decoder model, with\nprovide the answer. [20] supports keyword and entity search,\nT5-base architecture, already pre-trained on TriviaQA [37].\nit fails to accommodate phrase search, bi-gram search and\nWe fine-tune FiD on MRQA and then on Covid-QA, for a\nsemanticsearchlikeoursearchsystem.Bothofthesesystems\ntotal of 45000 steps with a batch size of 8.\ndo not perform triplet retrieval on knowledge graphs.\nC. Results\nD. Evaluation\nWe evaluate our framework qualitatively on the CORD-19\ndataset. We use two kinds of queries to test the performance We evaluate our framework on related open-source datasets\nofvariouscomponentsinourframework.First,forthephrase- due to the unavailability of labeled data for CORD-19. We\n“virus found in rhinolophus bats”, we get a list of passages evaluate the paragraph retrieval pipeline on another COVID-\nfrom paragraph retriever and multi-hop dense retriever along 19relateddataset,TREC-COVID[38].HereweusePrecision\nwith multiple triplets that talk about rhinolophus bats (as andNDCGasthemetric.NDCGistheratiooftheDiscounted\nshown in Fig.2). In case of a complex question like-”How CumulativeGain(DCG)ofarecommendedandidealorder.It\nmanyspeciesexistofthemammalsthatarethemainreservoir is evident that phrase search with MiniLM-L-6-v-2 re-ranker\nof coronaviruses?”, the complex QA system reasons over the yields better results when compared to results without re-\npassages retrieved by our multi-hop retriever and the reader ranking, as shown in Fig.4.\ngivesusthecorrectanswer.Itfirstretrievesapassagethattalks We evaluate the performance of the reader models on the\naboutthemainreservoirofcoronavirusi.e,bats,followedbya MRQA-dev data split by calculating the exact match and the",
    "tables": [
      [
        [
          "How many species exist of the mammals that are the main reservoir of coronaviruses?",
          ""
        ],
        [
          "Paragraph Retrieval",
          "Triplet Retrieval"
        ],
        [
          "High species diversity (about 1,150 in the world), high mobility and the fact that they represent a source of emerging infections for humans make bats one of the most epidemiologically relevant group of mammals to study disease ecology.",
          "Subject: Isolation and characterization of a bat SARS-like coronavirus that uses the ACE2 receptor Relation: References Object: Detection of Novel SARS Coronaviruses in Bats"
        ],
        [
          "Bats are the second largest order of mammals, comprising more than 1200 different species",
          "Subject: alpha-coronaviruses Relation: may be derived from Object: bat coronaviruses"
        ],
        [
          "Complex Question Answering",
          ""
        ],
        [
          "QA Response: 1200",
          ""
        ],
        [
          "Replication of MERS and SARS coronaviruses in bat cells offers insights to their ancestral origins Coronaviruses(CoVs) are important pathogens in animals and humans, responsible for a variety of respiratory, hepatic, and neurological diseases. Bats are an important reservoir of alpha coronaviruses and beta coronaviruses, which may jump to other species.",
          ""
        ],
        [
          "New Adenovirus Groups in Western Palaearctic Bats Bats are the second largest order of mammals, comprising more than 1200 different species. Their high vagility and the organization typically in social groups predispose them to infection and viral dissemination.",
          ""
        ]
      ]
    ],
    "text_stats": {
      "word_count": 608,
      "char_count": 4908,
      "line_count": 65,
      "table_count": 1
    }
  },
  {
    "page_number": 6,
    "text": "F1scoresforallsubsetsofthedataset.Weseethatthemodel’s\nperformance varies massively depending on the kind of data\nas seen in Table.1.\nHits\nnoisicerP\nPhrase with rerank Phrase without rerank\n1.00\n0.75\n0.50\n0.25\n0.00\n@1 @3 @5 @10 @50 @100\nHits\nGCDN\nlikequeryexpansionandqueryintentclassificationalongwith\nscalable semantic retrieval on top of the knowledge graph.\nACKNOWLEDGMENT\nWe thank Varun V, Advaith Shankar, Nim Sherpa and\nSaisubramaniam Gopalakrishnan for their assistance with\nfigures, and useful suggestions that helped improve the\nmanuscript.\nREFERENCES\n[1] S.Saxena,R.Sangani,S.Prasad,S.Kumar,M.Athale,R.Awhad,and\nV.Vaddina,“Large-scaleknowledgesynthesisandcomplexinformation\nretrieval from biomedical documents,” in 2022 IEEE International\nConferenceonBigData(BigData),2022,pp.2364–2369.\n[2] S. Sakji, A. D. Dibad, I. Kergourlay, S. Darmoni, and M. Joubert,\n“Information retrieval in context using various health terminologies,”\nin 2009 Third International Conference on Research Challenges in\nInformationScience. IEEE,2009,pp.453–458.\n[3] M.Al-Qahtani,S.Katsigiannis,andN.Ramzan,“Informationretrieval\nPhrase with rerank Phrase without rerank fromelectronichealthrecords,”EngineeringandTechnologyforHealth-\n0.8\ncare,p.117,2020.\n[4] W.Weiming,C.Shihong,C.Xi,andZ.Fan,“Knowledge-baseddocu-\nmentretrievalinmedicaldomain,”in2008InternationalSymposiumon\n0.6 KnowledgeAcquisitionandModeling. IEEE,2008,pp.226–230.\n[5] K.S.Jones,S.Walker,andS.E.Robertson,“Aprobabilisticmodelof\ninformation retrieval: development and comparative experiments: Part\n0.4 2,”Informationprocessing&management,vol.36,no.6,pp.809–840,\n2000.\n[6] J. Pennington, R. Socher, and C. D. Manning, “Glove: Global vectors\n0.2 for word representation,” in Proceedings of the 2014 conference on\nempiricalmethodsinnaturallanguageprocessing(EMNLP),2014,pp.\n1532–1543.\n0.0 [7] T.Mikolov,K.Chen,G.Corrado,andJ.Dean,“Efficientestimationof\n@1 @3 @5 @10 @50 @100 wordrepresentationsinvectorspace,”arXivpreprintarXiv:1301.3781,\n2013.\n[8] J.Devlin,M.-W.Chang,K.Lee,andK.Toutanova,“Bert:Pre-training\nFig.4. EvaluationofParagraphRetrievalonTREC-COVID.Phrasewithre- of deep bidirectional transformers for language understanding,” arXiv\nranker (denoted by blue) outperforms phrase without re-ranker (denoted by preprintarXiv:1810.04805,2018.\nred)acrossdifferenttop-kcomparisonsinbothPrecisionandNDCGmetrics. [9] W.Xiong,X.L.Li,S.Iyer,J.Du,P.Lewis,W.Y.Wang,Y.Mehdad,W.-\nt.Yih,S.Riedel,D.Kielaetal.,“Answeringcomplexopen-domainques-\ntionswithmulti-hopdenseretrieval,”arXivpreprintarXiv:2009.12756,\n2020.\nTABLEI [10] R. Jackson, I. Kartoglu, C. Stringer, G. Gorrell, A. Roberts, X. Song,\nEVALUATIONOFREADERSONMRQA-DEVSUBSETS H. Wu, A. Agrawal, K. Lui, T. Groza, D. Lewsley, D. Northwood,\nA. Folarin, R. Stewart, and R. Dobson, “Cogstack - experiences of\nExtractiveReader GenerativeReader deploying integrated information retrieval and extraction services in a\nSubset No.ofQuestions\nF1 ExactMatch large national health service foundation trust hospital,” BMC Medical\nExactMatch(%)\nscore(%) (%) InformaticsandDecisionMaking,vol.18,062018.\nSQUAD 10507 83.76 90.48 69.8\n[11] S.Sengan,G.Kamalam,J.Vellingiri,J.Gopal,P.Velayutham,V.Subra-\nTrivia-QA-web 7785 12.76 14.24 45.7\nSearchQA 16980 10.2 10.94 60.4 maniyaswamyetal.,“Medicalinformationretrievalsystemsfore-health\nHotpotQA 5901 60.78 76.74 41.5 carerecordsusingfuzzybasedmachinelearningmodel,”Microproces-\nNQShort 12836 64.78 76.74 48.9 sorsandMicrosystems,p.103344,2020.\nNewsQA 4212 52.84 66.62 36.2\n[12] Y.Wang,S.Mehrabi,M.R.Mojarad,D.Li,andH.Liu,“Retrievalof\nsemanticallysimilarhealthcarequestionsinhealthcareforums,”in2015\nInternationalConferenceonHealthcareInformatics. IEEE,2015,pp.\nV. CONCLUSION 517–518.\n[13] M.KumariandP.Ahlawat,“Intelligentinformationretrievalforreduc-\nIn this paper, we presented a complex information retrieval ingmissedcancerandimprovingthehealthcaresystem,”International\nframework built on COVID-19 related biomedical documents Journal of Information Retrieval Research (IJIRR), vol. 12, no. 1, pp.\n1–25,2022.\nthatcanperformbothlexicalandsemanticsearchandretrieve\n[14] C.Shorten,T.M.Khoshgoftaar,andB.Furht,“Deeplearningapplica-\nparagraphsalongwithaknowledgegraphconsistingoftriplets tionsforcovid-19,”JournalofbigData,vol.8,no.1,pp.1–54,2021.\nextracted from unstructured text. We also use faceted refine- [15] C.Wise,V.N.Ioannidis,M.R.Calvo,X.Song,G.Price,N.Kulkarni,\nR. Brand, P. Bhatia, and G. Karypis, “Covid-19 knowledge graph:\nment to filter the results. We demonstrate our complex QA\nacceleratinginformationretrievalanddiscoveryforscientificliterature,”\nsystem, which gives the researcher a pinpoint answer to the arXivpreprintarXiv:2007.12731,2020.\nquery asked. We find that this framework makes it easier for [16] A. Esteva, A. Kale, R. Paulus, K. Hashimoto, W. Yin, D. Radev, and\nR. Socher, “Covid-19 information retrieval with deep-learning based\nthe researcher to search for specific information from massive\nsemantic search, question answering, and abstractive summarization,”\ncorpora. In our future work, we plan to add functionalities NPJdigitalmedicine,vol.4,no.1,pp.1–9,2021.",
    "tables": [],
    "text_stats": {
      "word_count": 457,
      "char_count": 5124,
      "line_count": 91,
      "table_count": 0
    }
  },
  {
    "page_number": 7,
    "text": "[17] Q.Jin,Z.Yuan,G.Xiong,Q.Yu,H.Ying,C.Tan,M.Chen,S.Huang, ing a pandemic information retrieval test collection,” in ACM SIGIR\nX. Liu, and S. Yu, “Biomedical question answering: A survey of Forum,vol.54,no.1. ACMNewYork,NY,USA,2021,pp.1–12.\napproachesandchallenges,”ACMComputingSurveys(CSUR),vol.55,\nno.2,pp.1–36,2022.\n[18] Y. Lan, G. He, J. Jiang, J. Jiang, W. X. Zhao, and J.-R. Wen, “Com-\nplex knowledge base question answering: A survey,” arXiv preprint\narXiv:2108.06688,2021.\n[19] D. Su, Y. Xu, T. Yu, F. B. Siddique, E. J. Barezi, and P. Fung,\n“Caire-covid:Aquestionansweringandquery-focusedmulti-document\nsummarizationsystemforcovid-19scholarlyinformationmanagement,”\narXivpreprintarXiv:2005.03975,2020.\n[20] H. Ambavi, K. Vaishnaw, U. Vyas, A. Tiwari, and M. Singh, “Covid-\nexplorer: A multi-faceted ai-based search and visualization engine for\ncovid-19 information,” in Proceedings of the 29th ACM International\nConferenceonInformation&KnowledgeManagement,2020,pp.3365–\n3368.\n[21] N.ReimersandI.Gurevych,“Sentence-bert:Sentenceembeddingsusing\nsiamesebert-networks,”arXivpreprintarXiv:1908.10084,2019.\n[22] F. Zhu, W. Lei, C. Wang, J. Zheng, S. Poria, and T.-S. Chua, “Re-\ntrievingandreading:Acomprehensivesurveyonopen-domainquestion\nanswering,”arXivpreprintarXiv:2101.00774,2021.\n[23] P. Qi, H. Lee, O. Sido, C. D. Manning et al., “Answering open-\ndomainquestionsofvaryingreasoningstepsfromtext,”arXivpreprint\narXiv:2010.12527,2020.\n[24] A.Saxena,A.Tripathi,andP.Talukdar,“Improvingmulti-hopquestion\nansweringoverknowledgegraphsusingknowledgebaseembeddings,”\nin Proceedings of the 58th annual meeting of the association for\ncomputationallinguistics,2020,pp.4498–4507.\n[25] Z. Wang, L. Li, D. D. Zeng, and Y. Chen, “Attention-based multi-hop\nreasoningforknowledgegraph,”in2018IEEEInternationalConference\non Intelligence and Security Informatics (ISI). IEEE, 2018, pp. 211–\n213.\n[26] L. L. Wang, K. Lo, Y. Chandrasekhar, R. Reas, J. Yang, D. Eide,\nK. Funk, R. Kinney, Z. Liu, W. Merrill et al., “Cord-19: The covid-\n19openresearchdataset,”ArXiv,2020.\n[27] K. Kolluru, V. Adlakha, S. Aggarwal, S. Chakrabarti et al., “Openie6:\nIterative grid labeling and coordination analysis for open information\nextraction,”arXivpreprintarXiv:2010.03147,2020.\n[28] P. Norvig, “How to write a spelling corrector,” De: http://norvig.\ncom/spell-correct.html,2007.\n[29] W.Wang,F.Wei,L.Dong,H.Bao,N.Yang,andM.Zhou,“Minilm:\nDeep self-attention distillation for task-agnostic compression of pre-\ntrainedtransformers,”AdvancesinNeuralInformationProcessingSys-\ntems,vol.33,pp.5776–5788,2020.\n[30] T. Nguyen, M. Rosenberg, X. Song, J. Gao, S. Tiwary, R. Majumder,\nandL.Deng,“Msmarco:Ahumangeneratedmachinereadingcompre-\nhensiondataset,”inCoCo@NIPs,2016.\n[31] N. Francis, A. Green, P. Guagliardo, L. Libkin, T. Lindaaker,\nV. Marsault, S. Plantikow, M. Rydberg, P. Selmer, and A. Taylor,\n“Cypher: An evolving query language for property graphs,” in\nProceedings of the 2018 International Conference on Management\nof Data, ser. SIGMOD ’18. New York, NY, USA: Association\nfor Computing Machinery, 2018, p. 1433–1445. [Online]. Available:\nhttps://doi.org/10.1145/3183713.3190657\n[32] Y.Liu,M.Ott,N.Goyal,J.Du,M.Joshi,D.Chen,O.Levy,M.Lewis,\nL. Zettlemoyer, and V. Stoyanov, “Roberta: A robustly optimized bert\npretrainingapproach,”arXivpreprintarXiv:1907.11692,2019.\n[33] J. Johnson, M. Douze, and H. Je´gou, “Billion-scale similarity search\nwithgpus,”IEEETransactionsonBigData,vol.7,no.3,pp.535–547,\n2019.\n[34] G. Izacard and E. Grave, “Leveraging passage retrieval with gener-\native models for open domain question answering,” arXiv preprint\narXiv:2007.01282,2020.\n[35] A.Fisch,A.Talmor,R.Jia,M.Seo,E.Choi,andD.Chen,“Mrqa2019\nsharedtask:Evaluatinggeneralizationinreadingcomprehension,”arXiv\npreprintarXiv:1910.09753,2019.\n[36] T. Mo¨ller, A. Reina, R. Jayakumar, and M. Pietsch, “Covid-qa: A\nquestion answering dataset for covid-19,” in Proceedings of the 1st\nWorkshoponNLPforCOVID-19atACL2020,2020.\n[37] M.Joshi,E.Choi,D.S.Weld,andL.Zettlemoyer,“Triviaqa:Alarge\nscaledistantlysupervisedchallengedatasetforreadingcomprehension,”\narXivpreprintarXiv:1705.03551,2017.\n[38] E. Voorhees, T. Alam, S. Bedrick, D. Demner-Fushman, W. R. Hersh,\nK.Lo,K.Roberts,I.Soboroff,andL.L.Wang,“Trec-covid:construct-",
    "tables": [],
    "text_stats": {
      "word_count": 419,
      "char_count": 4274,
      "line_count": 74,
      "table_count": 0
    }
  }
]